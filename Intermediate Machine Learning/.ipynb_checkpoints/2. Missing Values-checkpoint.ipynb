{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44a0003",
   "metadata": {},
   "source": [
    "# Intermediate Machine Learning - Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2236f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eac4fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13580, 12) (13580,)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('melbourne_housing_snapshot/melb_data.csv')\n",
    "y = X.Price.copy()\n",
    "\n",
    "X.drop('Price', axis=1, inplace=True)\n",
    "X = X.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985442a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rooms               0\n",
       "Distance            0\n",
       "Postcode            0\n",
       "Bedroom2            0\n",
       "Bathroom            0\n",
       "Car                62\n",
       "Landsize            0\n",
       "BuildingArea     6450\n",
       "YearBuilt        5375\n",
       "Lattitude           0\n",
       "Longtitude          0\n",
       "Propertycount       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445cdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: X-> (10864, 12), y-> (10864,)\n",
      "valid: X-> (2716, 12), y-> (2716,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)\n",
    "\n",
    "print(f\"train: X-> {X_train.shape}, y-> {y_train.shape}\")\n",
    "print(f\"valid: X-> {X_valid.shape}, y-> {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eba0c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f418e",
   "metadata": {},
   "source": [
    "## Three Approaches\n",
    "\n",
    "1. **Drop columns with Missing Values:** model loses access to a lot of information\n",
    "2. **Imputation:** fills in the missing valueswith some number (mean) - usually leads to more accurate models than dropping the column\n",
    "3. **Extension to Imputation:** not just replacing but adding a new column with saying that the data was missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6bb91f",
   "metadata": {},
   "source": [
    "## 1 - Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8df80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop columns with missing values):\n",
      "183550.22137772635\n"
     ]
    }
   ],
   "source": [
    "first_X_train = X_train.dropna(axis=1)\n",
    "first_X_valid = X_valid.dropna(axis=1)\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "print(score_dataset(first_X_train, first_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e968e",
   "metadata": {},
   "source": [
    "# 2 - Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63cda6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Imputation):\n",
      "178166.46269899711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "print(\"MAE from Approach 2 (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798adb34",
   "metadata": {},
   "source": [
    "# 3 - Extended imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8706b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (An Extension to Imputation):\n",
      "178927.503183954\n"
     ]
    }
   ],
   "source": [
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "# Make new columns indicating what will be imputed\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "\n",
    "print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad360f4",
   "metadata": {},
   "source": [
    "Win: Approach 2!\n",
    "\n",
    "**Explanation:** The training data has 10864 rows and 12 columns, where three columns contain missing data. For each column, less than half of the entries are missing. Thus, dropping the columns removes a lot of useful information, and so it makes sense that imputation would perform better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
